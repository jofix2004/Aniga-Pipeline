{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "intro_md"
      },
      "source": [
        "# üè≠ ImgCraft Chapter Processor - Lightning AI Studio Runner\n",
        "## Setup and Run\n",
        "1. T·∫£i notebook n√†y l√™n m·ªôt v√πng l√†m vi·ªác tr·ªëng c·ªßa Lightning AI Studio.\n",
        "2. Ch·∫°y b∆∞·ªõc 1 ƒë·ªÉ t·∫£i model, clone project v√† c√†i ƒë·∫∑t m√¥i tr∆∞·ªùng.\n",
        "3. Ch·∫°y b∆∞·ªõc 2 ƒë·ªÉ kh·ªüi ƒë·ªông Server v√† nh·∫≠n public link qua Pinggy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "setup"
      },
      "outputs": [],
      "source": [
        "# @title 1. C√†i ƒë·∫∑t M√¥i tr∆∞·ªùng & Download Models cho Lightning AI Studio\n",
        "import os\n",
        "import subprocess\n",
        "\n",
        "def run(cmd): \n",
        "    print(f\"üñ•Ô∏è Running: {cmd}\")\n",
        "    try:\n",
        "        subprocess.run(cmd, shell=True, check=True)\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        print(f\"‚ö†Ô∏è Error on command: {cmd}\")\n",
        "        print(f\"‚ö†Ô∏è Exit status: {e.returncode}\")\n",
        "\n",
        "print(\"üì¶ System Dependencies...\")\n",
        "run(\"sudo apt-get update && sudo apt-get install -y aria2 libgl1-mesa-glx build-essential\")\n",
        "\n",
        "STUDIO_DIR = \"/teamspace/studios/this_studio\"\n",
        "os.chdir(STUDIO_DIR)\n",
        "\n",
        "# Clone Repo Aniga Pipeline (Ch·ª©a m√£ ngu·ªìn imgcraft)\n",
        "if not os.path.exists('Aniga-Pipeline'):\n",
        "    run(\"git clone https://github.com/jofix2004/Aniga-Pipeline.git\")\n",
        "else:\n",
        "    os.chdir('Aniga-Pipeline')\n",
        "    run(\"git fetch origin master\")\n",
        "    run(\"git reset --hard origin/master\")\n",
        "    os.chdir(STUDIO_DIR)\n",
        "\n",
        "# Clone ComfyUI\n",
        "if not os.path.exists(f\"{STUDIO_DIR}/ComfyUI\"):\n",
        "    run(\"git clone https://github.com/jofix2004/ComfyUI.git\")\n",
        "\n",
        "print(\"üì• Python Requirements...\")\n",
        "run(\"pip uninstall -y comfy-cli comfy\")\n",
        "run(f\"pip install -q -r {STUDIO_DIR}/Aniga-Pipeline/aniga_imgcraft_lightning/requirements.txt\")\n",
        "\n",
        "print(\"‚¨áÔ∏è Models...\")\n",
        "models = {\n",
        "    \"unet\": [(\"flux1-kontext-dev-fp8-e4m3fn.safetensors\", \"https://huggingface.co/6chan/flux1-kontext-dev-fp8/resolve/main/flux1-kontext-dev-fp8-e4m3fn.safetensors\")],\n",
        "    \"vae\": [(\"ae.sft\", \"https://huggingface.co/Isi99999/Upscalers/resolve/main/Flux/ae.sft\")],\n",
        "    \"clip\": [(\"clip_l.safetensors\", \"https://huggingface.co/Isi99999/Upscalers/resolve/main/Flux/clip_l.safetensors\"), \n",
        "             (\"t5xxl_fp8_e4m3fn.safetensors\", \"https://huggingface.co/Isi99999/Upscalers/resolve/main/Flux/t5xxl_fp8_e4m3fn.safetensors\")],\n",
        "    \"loras\": [(\"flux_1_turbo_alpha.safetensors\", \"https://huggingface.co/Isi99999/Upscalers/resolve/main/Flux/flux_1_turbo_alpha.safetensors\"),\n",
        "              (\"AniGaKontext_1024x64x1605_v4_000001400.safetensors\", \"https://huggingface.co/TranLinh2004/AniGaKontext2080v3_Full/resolve/main/AniGaKontext_1024x64x1605_v4_000001400.safetensors\")]\n",
        "}\n",
        "\n",
        "for folder, items in models.items():\n",
        "    dest = f\"{STUDIO_DIR}/ComfyUI/models/{folder}\"\n",
        "    os.makedirs(dest, exist_ok=True)\n",
        "    for fname, url in items:\n",
        "        if not os.path.exists(f\"{dest}/{fname}\"):\n",
        "            run(f\"aria2c -c -x 16 -s 16 -k 1M -d {dest} -o {fname} {url}\")\n",
        "\n",
        "print(\"‚úÖ M√¥i tr∆∞·ªùng & Models ƒë√£ s·∫µn s√†ng!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "run_server_lightning",
      "metadata": {
        "id": "run_server"
      },
      "outputs": [],
      "source": [
        "# @title 2. Kh·ªüi ƒë·ªông ImgCraft Server & Pinggy Tunnel\n",
        "import threading\n",
        "import time\n",
        "import subprocess\n",
        "import sys\n",
        "import os\n",
        "import re\n",
        "import gc\n",
        "import torch\n",
        "import importlib\n",
        "import uvicorn\n",
        "import nest_asyncio\n",
        "\n",
        "nest_asyncio.apply()\n",
        "\n",
        "STUDIO_DIR = \"/teamspace/studios/this_studio\"\n",
        "IMG_CRAFT_DIR = f\"{STUDIO_DIR}/Aniga-Pipeline/aniga_imgcraft_lightning\"\n",
        "\n",
        "os.chdir(IMG_CRAFT_DIR)\n",
        "if IMG_CRAFT_DIR not in sys.path:\n",
        "    sys.path.insert(0, IMG_CRAFT_DIR)\n",
        "\n",
        "# ========== NUCLEAR VRAM CLEANUP ==========\n",
        "print(\"üßπ [Step 1] Gi·∫£i ph√≥ng VRAM...\")\n",
        "\n",
        "_old_fp = None\n",
        "if 'imgcraft_server' in sys.modules:\n",
        "    _old_fp = getattr(sys.modules['imgcraft_server'].state, 'flux_processor', None)\n",
        "\n",
        "if _old_fp is not None:\n",
        "    try:\n",
        "        _old_fp.cleanup()\n",
        "    except:\n",
        "        pass\n",
        "    del _old_fp\n",
        "\n",
        "try:\n",
        "    import comfy.model_management as _mm\n",
        "    _mm.unload_all_models()\n",
        "    _mm.soft_empty_cache()\n",
        "except: pass\n",
        "\n",
        "gc.collect()\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.empty_cache()\n",
        "    torch.cuda.ipc_collect()\n",
        "\n",
        "# ========== RELOAD MODULES ==========\n",
        "print(\"üîÑ [Step 2] Reload modules...\")\n",
        "import imgcraft_core\n",
        "import imgcraft_server\n",
        "importlib.reload(imgcraft_core)\n",
        "importlib.reload(imgcraft_server)\n",
        "\n",
        "# ========== KILL TI·∫æN TR√åNH C≈® ==========\n",
        "print(\"üî™ [Step 3] Kill ti·∫øn tr√¨nh c≈©...\")\n",
        "subprocess.run(\"fuser -k 8001/tcp\", shell=True, stderr=subprocess.DEVNULL)\n",
        "subprocess.run(\"pkill -f uvicorn\", shell=True)\n",
        "subprocess.run(\"pkill -f 'ssh.*pinggy'\", shell=True)\n",
        "time.sleep(2)\n",
        "\n",
        "# ========== INIT M·ªöI ==========\n",
        "print(\"üì¶ [Step 4] Kh·ªüi t·∫°o FluxProcessor...\")\n",
        "imgcraft_server.state.flux_processor = imgcraft_core.FluxProcessor()\n",
        "\n",
        "print(\"üöÄ [Step 5] B·∫≠t Server (Port 8001)...\")\n",
        "server_config = uvicorn.Config(imgcraft_server.app, host=\"0.0.0.0\", port=8001, log_level=\"error\")\n",
        "server = uvicorn.Server(server_config)\n",
        "t = threading.Thread(target=server.run, daemon=True)\n",
        "t.start()\n",
        "time.sleep(5)\n",
        "\n",
        "print(\"üåê [Step 6] B·∫≠t Pinggy Tunnel...\")\n",
        "cmd = \"ssh -p 443 -o StrictHostKeyChecking=no -R0:localhost:8001 a.pinggy.io\"\n",
        "process = subprocess.Popen(cmd, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
        "\n",
        "print(\"=\"*50)\n",
        "print(\"üëáüëáüëá LINK TRUY C·∫¨P IMGCRAFT: üëáüëáüëá\")\n",
        "try:\n",
        "    url_printed = False\n",
        "    for line in iter(process.stdout.readline, ''):\n",
        "        if not url_printed and \"https://\" in line:\n",
        "            if \"dashboard.pinggy.io\" in line:\n",
        "                continue\n",
        "            match = re.search(r\"https://[a-zA-Z0-9._-]+\\.a\\.free\\.pinggy\\.link\", line)\n",
        "            if not match:\n",
        "                match = re.search(r\"https://[a-zA-Z0-9._-]+\\.pinggy\\.[a-z]+\", line)\n",
        "            if match:\n",
        "                print(f\"\\nüîó URL: {match.group(0)}\\n\")\n",
        "                print(\"=\"*50)\n",
        "                url_printed = True\n",
        "except KeyboardInterrupt:\n",
        "    process.kill()\n",
        "    print(\"\\nüõë Tunnel stopped.\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
